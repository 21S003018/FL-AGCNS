{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(50)\n"
     ]
    }
   ],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class DotDict(dict):\n",
    "#     def __init__(self, **kwds):\n",
    "#         self.update(kwds)\n",
    "#         self.__dict__ = self\n",
    "\n",
    "# path_sbm_train = \"data/SBM/SBM_CLUSTER_train.pkl\"\n",
    "# path_sbm_val = \"data/SBM/SBM_CLUSTER_val.pkl\"\n",
    "# path_sbm_test = \"data/SBM/SBM_CLUSTER_test.pkl\"\n",
    "# with open(path_sbm_train, 'rb') as f:\n",
    "#     sbm_train = pickle.load(f)\n",
    "# with open(path_sbm_val, 'rb') as f:\n",
    "#     sbm_val = pickle.load(f)\n",
    "# with open(path_sbm_test, 'rb') as f:\n",
    "#     sbm_test = pickle.load(f)\n",
    "# # sbm_train\n",
    "\n",
    "# # for tmp in sbm_train:\n",
    "# #     print(len(tmp.node_feat))\n",
    "# # sbm_train[0].node_feat\n",
    "# # edge_index = torch.tensor([[],[]])\n",
    "# # print(edge_index)\n",
    "# # print(torch.cat((edge_index, torch.nonzero(sbm_train[0].W).T+100), 1))\n",
    "# # x = torch.BoolTensor([0]*10)\n",
    "# # x[1:3] = True\n",
    "# # print(x)\n",
    "# # print([1,2]*2)\n",
    "# s_train = 0\n",
    "# for tmp in sbm_train:\n",
    "#     s_train += len(tmp.node_feat)\n",
    "# s_val = 0\n",
    "# for tmp in sbm_val:\n",
    "#     s_val += len(tmp.node_feat)\n",
    "# s_test = 0\n",
    "# for tmp in sbm_test:\n",
    "#     s_test += len(tmp.node_feat)\n",
    "# print(s_train, s_val, s_test, s_train + s_val+s_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch_geometric.data import Data\n",
    "# K=1000\n",
    "# NBTRAIN = len(sbm_train)\n",
    "# NBVAL = len(sbm_val)\n",
    "# NBTEST = len(sbm_test)\n",
    "\n",
    "# import torch\n",
    "# for k in range(K):\n",
    "#     print(k)\n",
    "#     idx_base=0\n",
    "#     edge_index = torch.LongTensor([[],[]])\n",
    "#     x = torch.tensor([])\n",
    "#     y = torch.LongTensor([])\n",
    "#     for idx_graph in range(k*int(NBTRAIN/K),(k+1)*int(NBTRAIN/K)):\n",
    "#         sub_graph = sbm_train[idx_graph]\n",
    "#         edge_index = torch.cat(\n",
    "#             (edge_index, torch.nonzero(sub_graph.W).T+idx_base), 1)\n",
    "#         x = torch.cat((x, torch.unsqueeze(sub_graph.node_feat, 1)), 0)\n",
    "#         y = torch.cat((y, sub_graph.node_label), 0)\n",
    "#         idx_base += len(sub_graph.node_feat)\n",
    "#     idx_train = idx_base\n",
    "#     for idx_graph in range(k*int(NBVAL/K), (k+1)*int(NBVAL/K)):\n",
    "#         sub_graph = sbm_val[idx_graph]\n",
    "#         edge_index = torch.cat(\n",
    "#             (edge_index, torch.nonzero(sub_graph.W).T+idx_base), 1)\n",
    "#         x = torch.cat((x, torch.unsqueeze(sub_graph.node_feat, 1)), 0)\n",
    "#         y = torch.cat((y, sub_graph.node_label), 0)\n",
    "#         idx_base += len(sub_graph.node_feat)\n",
    "#     idx_val = idx_base\n",
    "#     for idx_graph in range(k*int(NBTEST/K), (k+1)*int(NBTEST/K)):\n",
    "#         sub_graph = sbm_test[idx_graph]\n",
    "#         edge_index = torch.cat(\n",
    "#             (edge_index, torch.nonzero(sub_graph.W).T+idx_base), 1)\n",
    "#         x = torch.cat((x, torch.unsqueeze(sub_graph.node_feat, 1)), 0)\n",
    "#         y = torch.cat((y, sub_graph.node_label), 0)\n",
    "#         idx_base += len(sub_graph.node_feat)\n",
    "#     idx_test = idx_base\n",
    "\n",
    "#     x = torch.zeros(x.shape[0], 7).scatter(1, torch.tensor(x,dtype=torch.int64), 1)[:, 1:]\n",
    "#     train_mask = torch.BoolTensor([0]*idx_base)\n",
    "#     train_mask[0:idx_train] = True\n",
    "#     val_mask = torch.BoolTensor([0]*idx_base)\n",
    "#     val_mask[idx_train:idx_val] = True\n",
    "#     test_mask = torch.BoolTensor([0]*idx_base)\n",
    "#     test_mask[idx_val:idx_test] = True\n",
    "#     # with open(\"data/SBM/{}_uncopynode.pkl\".format(k), \"wb\") as f:\n",
    "#     #     pickle.dump(Data(edge_index=edge_index, x = x, y = y, train_mask = train_mask, val_mask = val_mask, test_mask = val_mask), f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import Gat,Sage\n",
    "from torch import optim\n",
    "import pickle\n",
    "import torch.nn.functional as F\n",
    "import utils\n",
    "import torch.nn as nn\n",
    "import torch_geometric.nn as gnn\n",
    "\n",
    "\n",
    "# model = Gat(6,6).to('cuda:0')\n",
    "datas = []\n",
    "for i in range(1000):\n",
    "    path = f'data/SBM/{i}_uncopynode.pkl'\n",
    "    with open(path, 'rb') as f:\n",
    "        datas.append(pickle.load(f).to('cuda:0'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user1/anaconda3/envs/test/lib/python3.8/site-packages/torch/nn/functional.py:1805: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter1, loss:1.7551698240041733,train_acc:0.23264149629279077\n",
      "Iter2, loss:1.6739285281896592,train_acc:0.33090114494790884\n",
      "Iter3, loss:1.6265976947546006,train_acc:0.36335642236178745\n",
      "Iter4, loss:1.5885578683614732,train_acc:0.3740679216735574\n",
      "Iter5, loss:1.5606922438144684,train_acc:0.384665871952323\n",
      "Iter6, loss:1.544199174642563,train_acc:0.39441720376530964\n",
      "Iter7, loss:1.5356242880821227,train_acc:0.4027025862625091\n",
      "Iter8, loss:1.5308883451223374,train_acc:0.40906894432731555\n",
      "Iter9, loss:1.5275925365686416,train_acc:0.41423943182294454\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/user1/FL-AGCNS/test.ipynb Cell 5'\u001b[0m in \u001b[0;36m<cell line: 36>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B3090.local/home/user1/FL-AGCNS/test.ipynb#ch0000006vscode-remote?line=38'>39</a>\u001b[0m \u001b[39mfor\u001b[39;00m \u001b[39miter\u001b[39m, data \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(datas):\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B3090.local/home/user1/FL-AGCNS/test.ipynb#ch0000006vscode-remote?line=39'>40</a>\u001b[0m     preds \u001b[39m=\u001b[39m model(data\u001b[39m.\u001b[39mx, data\u001b[39m.\u001b[39medge_index)\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B3090.local/home/user1/FL-AGCNS/test.ipynb#ch0000006vscode-remote?line=40'>41</a>\u001b[0m     loss \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mcross_entropy(preds[data\u001b[39m.\u001b[39mtrain_mask],data\u001b[39m.\u001b[39my[data\u001b[39m.\u001b[39mtrain_mask])\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B3090.local/home/user1/FL-AGCNS/test.ipynb#ch0000006vscode-remote?line=41'>42</a>\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B3090.local/home/user1/FL-AGCNS/test.ipynb#ch0000006vscode-remote?line=42'>43</a>\u001b[0m     loss\u001b[39m.\u001b[39mbackward()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# class Gcn(nn.Module):\n",
    "#     def __init__(self, nfeat, nclass):\n",
    "#         super(Gcn, self).__init__()\n",
    "#         hdim = 146\n",
    "#         self.lnin = nn.Linear(nfeat,hdim)\n",
    "#         self.gcn = gnn.GCNConv(hdim,hdim)\n",
    "#         self.gcn1 = gnn.GCNConv(nfeat, hdim)\n",
    "#         # self.gcn2 = gnn.GCNConv(hdim, hdim)\n",
    "#         # self.gcn3 = gnn.GCNConv(hdim, hdim)\n",
    "#         self.gcn4 = gnn.GCNConv(hdim, nclass)\n",
    "#         self.lnout = nn.Linear(hdim, nclass)\n",
    "#         return\n",
    "\n",
    "#     def forward(self, x, edge_index):\n",
    "#         # x = self.gcn1(x, edge_index)\n",
    "#         # x = F.relu(x)\n",
    "#         # x = self.gcn2(x, edge_index)\n",
    "#         # x = F.relu(x)\n",
    "#         # x = self.gcn3(x, edge_index)\n",
    "#         # x = F.relu(x)\n",
    "#         # x = self.gcn4(x, edge_index)\n",
    "#         x = self.lnin(x)\n",
    "#         x = self.gcn(x,edge_index)\n",
    "#         x = F.relu(x)\n",
    "#         x = self.lnout(x)\n",
    "#         return x\n",
    "from models import Appnp,Sage\n",
    "model = Sage(6,6).to('cuda:0')\n",
    "model.train()\n",
    "\n",
    "# optimizer = optim.SGD(\n",
    "#     model.parameters(), lr=0.1,momentum=0.9, weight_decay=1e-6)\n",
    "optimizer = optim.Adam(\n",
    "    model.parameters(), lr=0.001, weight_decay=1e-6)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer,mode='min',factor=0.5,patience=5)\n",
    "for epoch in range(1000):\n",
    "    losses = 0\n",
    "    accus = 0\n",
    "    for iter, data in enumerate(datas):\n",
    "        preds = model(data.x, data.edge_index)\n",
    "        loss = F.cross_entropy(preds[data.train_mask],data.y[data.train_mask])\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses += loss.item()\n",
    "        accus += utils.accuracy(preds[data.train_mask],\n",
    "                                data.y[data.train_mask])\n",
    "    print('Iter{}, loss:{},train_acc:{}'.format(epoch+1, losses/(iter+1), accus/(iter+1)))\n",
    "    scheduler.step(losses/(iter+1))\n",
    "    # break\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "107ca912c34283f1e783f874d23ab65f09505e75747332ac35ecc882c819ad56"
  },
  "kernelspec": {
   "display_name": "Python 3.8.11 ('test')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
