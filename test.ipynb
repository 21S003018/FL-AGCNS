{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pickle\n",
    "# # path = \"data/Physics/0_uncopynode.pkl\"\n",
    "# # with open(path, 'rb') as f:\n",
    "# #     data = pickle.load(f)\n",
    "# # print(data.edge_index.max())\n",
    "# # print(len(data.x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# # print(data.edge_index.shape, data.train_mask.shape)\n",
    "# # s = set()\n",
    "# # for e in data.edge_index[1]:\n",
    "# #     s.add(e.item())\n",
    "# # print(len(s))\n",
    "# # data.edge_index\n",
    "# # data.train_mask\n",
    "\n",
    "# # path = 'data/SBM/0_uncopynode.pkl'\n",
    "# # with open(path, 'rb') as f:\n",
    "# #     data = pickle.load(f)\n",
    "# # print(data.y.min(),data.y.max())\n",
    "# # print(data.edge_index[0].max())\n",
    "# # print(data.edge_index[1].max())\n",
    "# # print(len(data.x[0]))\n",
    "# import torch\n",
    "# x = torch.Tensor([0,0])\n",
    "# print(x.to('cuda').grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class DotDict(dict):\n",
    "#     def __init__(self, **kwds):\n",
    "#         self.update(kwds)\n",
    "#         self.__dict__ = self\n",
    "\n",
    "# path_sbm_train = \"data/SBM/SBM_CLUSTER_train.pkl\"\n",
    "# path_sbm_val = \"data/SBM/SBM_CLUSTER_val.pkl\"\n",
    "# path_sbm_test = \"data/SBM/SBM_CLUSTER_test.pkl\"\n",
    "# with open(path_sbm_train, 'rb') as f:\n",
    "#     sbm_train = pickle.load(f)\n",
    "# with open(path_sbm_val, 'rb') as f:\n",
    "#     sbm_val = pickle.load(f)\n",
    "# with open(path_sbm_test, 'rb') as f:\n",
    "#     sbm_test = pickle.load(f)\n",
    "# # sbm_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for tmp in sbm_train:\n",
    "# #     print(len(tmp.node_feat))\n",
    "# # sbm_train[0].node_feat\n",
    "# # edge_index = torch.tensor([[],[]])\n",
    "# # print(edge_index)\n",
    "# # print(torch.cat((edge_index, torch.nonzero(sbm_train[0].W).T+100), 1))\n",
    "# # x = torch.BoolTensor([0]*10)\n",
    "# # x[1:3] = True\n",
    "# # print(x)\n",
    "# # print([1,2]*2)\n",
    "# torch.nonzero(sbm_train[0].node_feat)\n",
    "\n",
    "# torch.nonzero(sbm_train[0].W).T[:,torch.nonzero(sbm_train[0].W).T[0] == 20]\n",
    "# for index in [  9,  13,  15,  19,  23,  24,  26,  31,  35,  41,  51,  52,  55,  58,\n",
    "#           64,  65,  67,  72,  75,  76,  78,  80,  84,  86,  87,  89,  90,  92,\n",
    "#           93,  94,  96,  99, 101, 102, 105, 111, 115]:\n",
    "#     print(sbm_train[0].node_label[index])\n",
    "# # s_train = 0\n",
    "# # for tmp in sbm_train:\n",
    "# #     s_train += len(tmp.node_feat)\n",
    "# # s_val = 0\n",
    "# # for tmp in sbm_val:\n",
    "# #     s_val += len(tmp.node_feat)\n",
    "# # s_test = 0\n",
    "# # for tmp in sbm_test:\n",
    "# #     s_test += len(tmp.node_feat)\n",
    "# # print(s_train, s_val, s_test, s_train + s_val+s_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch_geometric.data import Data\n",
    "# K=1000\n",
    "# NBTRAIN = len(sbm_train)\n",
    "# NBVAL = len(sbm_val)\n",
    "# NBTEST = len(sbm_test)\n",
    "\n",
    "# import torch\n",
    "# for k in range(K):\n",
    "#     print(k)\n",
    "#     idx_base=0\n",
    "#     edge_index = torch.LongTensor([[],[]])\n",
    "#     x = torch.tensor([])\n",
    "#     y = torch.LongTensor([])\n",
    "#     for idx_graph in range(k*int(NBTRAIN/K),(k+1)*int(NBTRAIN/K)):\n",
    "#         sub_graph = sbm_train[idx_graph]\n",
    "#         edge_index = torch.cat(\n",
    "#             (edge_index, torch.nonzero(sub_graph.W).T+idx_base), 1)\n",
    "#         x = torch.cat((x, torch.unsqueeze(sub_graph.node_feat, 1)), 0)\n",
    "#         y = torch.cat((y, sub_graph.node_label), 0)\n",
    "#         idx_base += len(sub_graph.node_feat)\n",
    "#     # print(x.size(), edge_index, idx_base)\n",
    "#     idx_train = idx_base\n",
    "#     for idx_graph in range(k*int(NBVAL/K), (k+1)*int(NBVAL/K)):\n",
    "#         sub_graph = sbm_val[idx_graph]\n",
    "#         edge_index = torch.cat(\n",
    "#             (edge_index, torch.nonzero(sub_graph.W).T+idx_base), 1)\n",
    "#         x = torch.cat((x, torch.unsqueeze(sub_graph.node_feat, 1)), 0)\n",
    "#         y = torch.cat((y, sub_graph.node_label), 0)\n",
    "#         idx_base += len(sub_graph.node_feat)\n",
    "#     # print(x.size(), edge_index, idx_base)\n",
    "#     idx_val = idx_base\n",
    "#     for idx_graph in range(k*int(NBTEST/K), (k+1)*int(NBTEST/K)):\n",
    "#         sub_graph = sbm_test[idx_graph]\n",
    "#         edge_index = torch.cat(\n",
    "#             (edge_index, torch.nonzero(sub_graph.W).T+idx_base), 1)\n",
    "#         x = torch.cat((x, torch.unsqueeze(sub_graph.node_feat, 1)), 0)\n",
    "#         y = torch.cat((y, sub_graph.node_label), 0)\n",
    "#         idx_base += len(sub_graph.node_feat)\n",
    "#     # print(x.size(), edge_index, idx_base)\n",
    "#     idx_test = idx_base\n",
    "\n",
    "#     x = torch.zeros(x.shape[0], 7).scatter(1, torch.tensor(x,dtype=torch.int64), 1)[:, 1:]\n",
    "#     train_mask = torch.BoolTensor([0]*idx_base)\n",
    "#     train_mask[0:idx_train] = True\n",
    "#     val_mask = torch.BoolTensor([0]*idx_base)\n",
    "#     val_mask[idx_train:idx_val] = True\n",
    "#     test_mask = torch.BoolTensor([0]*idx_base)\n",
    "#     test_mask[idx_val:idx_test] = True\n",
    "#     with open(\"data/SBM/{}_uncopynode.pkl\".format(k), \"wb\") as f:\n",
    "#         pickle.dump(Data(edge_index=edge_index, x = x, y = y, train_mask = train_mask, val_mask = val_mask, test_mask = val_mask), f)\n",
    "#     # break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import Gat, Sage\n",
    "from torch import optim\n",
    "import pickle\n",
    "import torch.nn.functional as F\n",
    "import utils\n",
    "import torch.nn as nn\n",
    "import torch_geometric.nn as gnn\n",
    "\n",
    "\n",
    "# model = Gat(6,6).to('cuda:0')\n",
    "datas = []\n",
    "for i in range(1000):\n",
    "    path = f'data/SBM/{i}_uncopynode.pkl'\n",
    "    with open(path, 'rb') as f:\n",
    "        datas.append(pickle.load(f).to('cuda:0'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Gcn(nn.Module):\n",
    "#     def __init__(self, nfeat, nclass):\n",
    "#         super(Gcn, self).__init__()\n",
    "#         hdim = 146\n",
    "#         self.lnin = nn.Linear(nfeat,hdim)\n",
    "#         self.gcn = gnn.GCNConv(hdim,hdim)\n",
    "#         self.gcn1 = gnn.GCNConv(nfeat, hdim)\n",
    "#         # self.gcn2 = gnn.GCNConv(hdim, hdim)\n",
    "#         # self.gcn3 = gnn.GCNConv(hdim, hdim)\n",
    "#         self.gcn4 = gnn.GCNConv(hdim, nclass)\n",
    "#         self.lnout = nn.Linear(hdim, nclass)\n",
    "#         return\n",
    "\n",
    "#     def forward(self, x, edge_index):\n",
    "#         # x = self.gcn1(x, edge_index)\n",
    "#         # x = F.relu(x)\n",
    "#         # x = self.gcn2(x, edge_index)\n",
    "#         # x = F.relu(x)\n",
    "#         # x = self.gcn3(x, edge_index)\n",
    "#         # x = F.relu(x)\n",
    "#         # x = self.gcn4(x, edge_index)\n",
    "#         x = self.lnin(x)\n",
    "#         x = self.gcn(x,edge_index)\n",
    "#         x = F.relu(x)\n",
    "#         x = self.lnout(x)\n",
    "#         return x\n",
    "from models import Appnp, Sage\n",
    "model = Sage(6, 6).to('cuda:0')\n",
    "model.train()\n",
    "\n",
    "# optimizer = optim.SGD(\n",
    "#     model.parameters(), lr=0.1,momentum=0.9, weight_decay=1e-6)\n",
    "optimizer = optim.Adam(\n",
    "    model.parameters(), lr=0.001, weight_decay=1e-6)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='min', factor=0.5, patience=5)\n",
    "for epoch in range(1000):\n",
    "    losses = 0\n",
    "    accus = 0\n",
    "    for iter, data in enumerate(datas):\n",
    "        preds = model(data.x, data.edge_index)\n",
    "        loss = F.cross_entropy(preds[data.train_mask], data.y[data.train_mask])\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses += loss.item()\n",
    "        accus += utils.accuracy(preds[data.train_mask],\n",
    "                                data.y[data.train_mask])\n",
    "    print('Iter{}, loss:{},train_acc:{}'.format(\n",
    "        epoch+1, losses/(iter+1), accus/(iter+1)))\n",
    "    scheduler.step(losses/(iter+1))\n",
    "    # break\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e27ccc4603250ab3abeb046d8ea1d0ecb320aa3746dcee4c0646124a7f5fa178"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
