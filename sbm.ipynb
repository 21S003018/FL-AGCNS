{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import SonNet,DynamicSonNet\n",
    "import pickle\n",
    "import torch, time\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def accuracy(output, labels):\n",
    "    '''\n",
    "    get accuracy\n",
    "    :param output:\n",
    "    :param labels:\n",
    "    :return:\n",
    "    '''\n",
    "    preds = output.max(1)[1].type_as(labels)\n",
    "    correct = preds.eq(labels).double()\n",
    "    correct = correct.sum().item()\n",
    "    return correct / len(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "datas = []\n",
    "for i in range(1000):\n",
    "    path = f'data/SBM/{i}_uncopynode.pkl'\n",
    "    with open(path, 'rb') as f:\n",
    "        datas.append(pickle.load(f).to('cuda:0'))\n",
    "torch.cuda.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update code\n",
    "# supermask = [5, 2, 1+12*1, 4+12*2, 5+12*3, (5+12*4)*0, (5+12*5)*0, 5]  # random sure\n",
    "# supermask = [3, 4, 5+12*1, 9+12*2, 2, 12+12*4, 0, 2] # agcns sure\n",
    "# supermask = [5, 10, 6+12*1, 1+12*2, 2, 0, 0, 5]  # graphnas sure\n",
    "# supermask = [3, 1, 1+12*1, 10+12*2, 2+12*2, 0, 0, 4]  # darts sure\n",
    "# supermask = [4, 1, 1+12*1, 1+12*2, 10, 2, 0, 4]  # fednas sure\n",
    "# supermask = [5, 8, 3+12*1, 1+12*2, 10+12*1, 0, 0, 4] # rl\n",
    "supermask = [5, 4, 4+12*1, 4+12*2, 4+12*3, (4+12*4)*1, (4+12*5)*1, 5]  # try\n",
    "with open('tmp.pkl', 'wb') as f:\n",
    "    pickle.dump(supermask, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0., 0., 1.])\n",
      "Iter1, loss:1.6383319321870804,train_acc:0.3199542666654383,val_acc:0.32138607251551937,test_acc:0.3236557709312128,use_time:15\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_38980/948794582.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m             preds[data.train_mask], data.y[data.train_mask], weight=data.weight)\n\u001b[1;32m     20\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mlosses\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    361\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train model\n",
    "model = SonNet(6,6).to('cuda:0')\n",
    "model.train()\n",
    "optimizer = optim.Adam(\n",
    "    model.parameters(), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode='min', factor=0.5, patience=5)\n",
    "st_time = time.time()\n",
    "for epoch in range(50):\n",
    "    losses = 0\n",
    "    train_accu = 0\n",
    "    val_accu = 0\n",
    "    test_accu = 0\n",
    "    best_val_accu = 0\n",
    "    for iter, data in enumerate(datas):\n",
    "        preds = model(data.x, data.edge_index)\n",
    "        labels = data.y[data.train_mask]\n",
    "        loss = F.cross_entropy(\n",
    "            preds[data.train_mask], data.y[data.train_mask], weight=data.weight)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        losses += loss.item()\n",
    "        train_accu += accuracy(preds[data.train_mask],\n",
    "                                data.y[data.train_mask])\n",
    "        val_accu += accuracy(preds[data.val_mask],\n",
    "                                data.y[data.val_mask])\n",
    "        test_accu += accuracy(preds[data.test_mask],\n",
    "                                data.y[data.test_mask])\n",
    "    if val_accu > best_val_accu:\n",
    "        best_val_accu = val_accu\n",
    "        torch.save(model.state_dict(), 'sbm_model.pth')\n",
    "        print('Iter{}, loss:{},train_acc:{},val_acc:{},test_acc:{},use_time:{}'.format(\n",
    "            epoch+1, losses/(iter+1), train_accu/(iter+1), val_accu/(iter+1), test_accu/(iter+1), round(time.time()-st_time)))\n",
    "    scheduler.step(losses/(iter+1))\n",
    "\n",
    "test_accu = 0\n",
    "model.load_state_dict(torch.load('sbm_model.pth'))\n",
    "model.eval()\n",
    "for iter, data in enumerate(datas):\n",
    "    preds = model(data.x, data.edge_index)\n",
    "    test_accu += accuracy(preds[data.test_mask],\n",
    "                            data.y[data.test_mask])*len(data.y[data.test_mask])/116820\n",
    "print(f'test accu:{test_accu}')\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e27ccc4603250ab3abeb046d8ea1d0ecb320aa3746dcee4c0646124a7f5fa178"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
